# 漫画图片翻译器

一键翻译漫画图片中的文字，支持日语、中文、英语等多种语言，提供完整的可视化编辑功能。

基于 [zyddnys/manga-image-translator](https://github.com/zyddnys/manga-image-translator) 核心引擎开发。

---

## 🚀 快速开始

### 📥 下载安装

#### 1. 下载程序

前往 [GitHub Releases](https://github.com/hgmzhn/manga-translator-ui/releases) 下载最新版本

**版本选择：**
- **CPU 版本**：适用于所有电脑
- **GPU 版本**：需要支持 CUDA 12.x 的 NVIDIA 显卡

**分卷下载说明：**
- 如果下载文件被分成多个压缩包（如 `part1.rar`, `part2.rar`...）
- 请下载**所有分卷**到同一文件夹
- 只需解压第一个分卷（`part1.rar`），其他分卷会自动解压

#### 2. 解压运行

1. 解压下载的压缩包到任意目录
2. 双击运行 `app.exe`
3. 首次运行会自动加载模型（需要几分钟）

#### 3. 开始翻译

1. **关闭 GPU**（仅 CPU 版本）：如果使用 CPU 版本，请在"基础设置"中取消勾选"使用 GPU"
2. **设置输出目录**：在主界面点击"选择输出文件夹"，指定翻译结果的保存位置
3. **添加图片**：点击"添加文件"或直接拖拽图片到窗口
4. **选择翻译器**：在设置中选择翻译引擎
5. **开始翻译**：点击"开始翻译"按钮
6. **查看结果**：翻译完成后会自动保存到输出目录

---

## ✨ 功能特性

### 核心功能

- **🔍 智能文本检测**：自动识别漫画中的文字区域
- **📝 多语言 OCR**：支持日语、中文、英语等多种语言识别
- **🌐 30+ 翻译引擎**：离线翻译器（Sugoi、NLLB 等）、在线翻译器（Google Gemini、OpenAI、DeepL 等）
- **🎯 高质量翻译**：使用多模态 AI 模型（GPT-4o、Gemini），结合图片上下文进行翻译，准确率更高
- **🎨 图像修复**：自动擦除原文并智能填充背景
- **✍️ 智能嵌字**：自动排版译文，支持多种字体和样式
- **🤖 AI 断句**：支持 OpenAI、Gemini 翻译器的智能断句功能
- **📦 批量处理**：一次处理整个文件夹的图片

### 可视化编辑器

提供强大的图形化编辑工具，支持精确调整翻译结果：

#### 区域编辑
- **移动**：拖拽文本区域到任意位置
- **旋转**：使用旋转手柄进行 0-360° 精确旋转
- **变形**：顶点编辑、边缘调整、自由变形
- **编辑形状**：选中文本框后，点击工具栏的"编辑形状"按钮，在空白区域拖动对角线增加新的蓝框

> **💡 OCR 识别最佳实践**：建议在编辑器中调整文本框，确保**一个蓝框里只有一行字**，不然 48px 和 32px 可能无法正确识别到文字。

#### 文本编辑
- **手动翻译**：直接编辑译文内容
- **样式调整**：字体、大小、颜色、对齐方式
- **方向控制**：水平/垂直文字方向

#### 蒙版编辑
- **画笔工具**：手动绘制文本擦除区域
- **橡皮擦**：修正蒙版错误
- **蒙版优化**：自动优化擦除效果

#### 高级功能
- **撤销/重做**：完整的操作历史管理
- **批量操作**：多选、批量修改属性
- **实时预览**：即时查看翻译效果

### 用户界面

- **现代化设计**：基于 PyQt6 的流畅界面
- **拖拽支持**：直接拖拽图片到窗口
- **实时日志**：查看翻译进度和错误信息
- **配置管理**：保存和加载自定义配置

---

## ⚙️ 常用设置

### 翻译器配置

**离线翻译器**（无需网络）：
- **Sugoi**：日→英翻译（默认）
- **NLLB**：多语言翻译
- **NLLB (Big)**：大模型多语言翻译
- **M2M100**：多语言翻译
- **M2M100 (Big)**：大模型多语言翻译
- **mBART50**：多语言翻译
- **JParaCrawl**：日语翻译
- **JParaCrawl (Big)**：大模型日语翻译
- **Qwen2**：通义千问翻译
- **Qwen2 (Big)**：大模型通义千问翻译
- **离线翻译**：通用离线翻译

**在线翻译器**（需要 API Key）：
- **Google Gemini**：Google Gemini 翻译
- **OpenAI**：OpenAI ChatGPT 翻译
- **DeepL**：DeepL 翻译
- **百度翻译**：百度翻译 API
- **有道翻译**：有道翻译 API
- **彩云小译**：彩云小译 API
- **Papago**：Naver Papago 翻译
- **Sakura**：Sakura 翻译
- **Groq**：Groq 翻译

**高质量翻译器**（需要 API Key，推荐）：
- **高质量翻译 OpenAI**：使用 GPT-4o 等多模态模型，结合图片上下文翻译
- **高质量翻译 Gemini**：使用 Gemini 多模态模型，结合图片上下文翻译

**高质量翻译器的优势**：
- 📸 **多模态理解**：AI 可以"看到"图片内容，理解上下文
- 🎯 **更准确**：结合图片信息，翻译更符合场景
- 📝 **批量处理**：一次发送多张图片，AI 理解整体剧情
- 🔧 **自定义提示词**：支持自定义翻译风格和术语表

**其他选项**：
- **原文**：不翻译，保留原文
- **无**：仅检测和擦除文本，不翻译

### OCR 模型

- **48px**：默认模型，推荐使用
- **48px_ctc**：CTC 模型，识别准确率更高
- **mocr**：Manga OCR 专用模型
- **paddleocr**：PaddleOCR 引擎

### 字体设置

程序会自动加载 `fonts` 目录下的所有字体文件。

**添加自定义字体：**
1. 将字体文件（`.ttf` 或 `.otf`）复制到 `fonts` 目录
2. 重启程序
3. 在设置中选择新字体

### 自定义导出原文模版

**用途**：自定义导出原文的格式，方便使用外部工具翻译

**模版文件位置**：`examples/translation_template.json`

**工作原理**：
- 模版定义了**一组文本框**的格式
- 导出时，程序会按照模版中的条目数量分组
- **重复的是文本框部分**，而不是整个 JSON 结构
- 例如：模版有 3 个占位符对，则每 3 个文本框作为一组输出

**示例模版**（3 个文本框一组）：
```json
{
    "<original>": "<translated>",
    "<original>": "<translated>",
    "<original>": "<translated>"
}
```

**导出效果示例**：
假设检测到 6 个文本框，使用上述 3 个占位符的模版，导出结果如下：

```json
{
    "你好": "Hello",
    "世界": "World",
    "欢迎": "Welcome",
    "再见": "Goodbye",
    "谢谢": "Thank you",
    "早安": "Good morning"
}
```

**使用说明**：
1. 编辑 `examples/translation_template.json` 文件
2. 定义一组文本框的格式（可以是 1 个、3 个或任意数量）
3. 使用 `<original>` 和 `<translated>` 作为占位符
4. 导出原文时，每组文本框会重复使用这个格式
5. 手动翻译后，使用"导入翻译并渲染"功能导入

**注意事项**：
- 模版中有几个占位符对，就会每几个文本框分为一组
- 如果文本框总数不是模版条目数的整数倍，最后一组会包含剩余的所有文本框

### AI 断句功能

**支持范围**：支持 OpenAI、Gemini 翻译器（包括高质量模式）

**作用**：使用 AI 智能断句，自动优化文本换行

**工作原理**：
- 在翻译请求中添加 `[Original regions: X]` 前缀
- 告诉 AI 原文有多少个文本区域
- AI 根据原文区域数量智能断句
- **不会增加 API 调用次数**，只是在同一次调用中添加额外信息

**启用方法**：
1. 选择支持的翻译器（OpenAI、Gemini、高质量翻译 OpenAI、高质量翻译 Gemini）
2. 在渲染设置中勾选"AI断句"
3. 开始翻译

### 工作流程说明

程序提供了一个"翻译流程模式"下拉菜单，包含 4 种工作流程：

#### 1. 正常翻译流程（默认）

**用途**：直接翻译图片

**步骤**：
1. 添加图片文件或文件夹
2. 选择翻译器和目标语言
3. 点击"开始翻译"
4. 翻译完成后，结果保存在输出文件夹

#### 2. 导出翻译

**用途**：翻译后导出翻译结果到 TXT 文件

**步骤**：
1. 选择"导出翻译"模式
2. 勾选"图片可编辑"（自动生成 JSON 文件）
3. 开始翻译
4. 程序会：
   - 完整翻译图片
   - 生成 `_translations.json` 文件
   - 生成 `_translated.txt` 文件（包含翻译结果）

#### 3. 导出原文

**用途**：仅检测和识别文本，导出原文到 TXT 文件，不进行翻译

**步骤**：
1. 选择"导出原文"模式
2. 勾选"图片可编辑"（自动生成 JSON 文件）
3. 点击"仅生成原文模板"
4. 程序会：
   - 检测文本区域
   - OCR 识别原文
   - 生成 `_translations.json` 文件
   - 生成 `_original.txt` 文件（包含原文）
   - **不进行翻译**，直接停止

**后续手动翻译**：
1. 打开 `manga_translator_work/originals/图片名_original.txt` 文件
2. 将原文翻译成目标语言
3. **直接在 `_original.txt` 文件中修改**（或直接修改 JSON 文件的 `translation` 字段）

#### 4. 导入翻译并渲染

**用途**：从 TXT 或 JSON 文件导入翻译内容，重新渲染图片，不进行翻译

**步骤**：
1. 选择"导入翻译并渲染"模式
2. 添加之前翻译过的图片（确保有对应的 `_translations.json` 文件）
3. 点击"导入翻译并渲染"
4. 程序会：
   - **预处理**：如果存在 `_translated.txt` 或 `_original.txt` 文件，先将 TXT 内容导入到 JSON 文件
   - **加载翻译**：从 JSON 文件加载翻译内容
   - **渲染图片**：使用加载的翻译内容渲染图片
   - **不进行翻译**，直接渲染

**使用场景**：
- 修改了 TXT 文件中的翻译内容，需要导入并重新渲染
- 修改了 JSON 文件中的翻译内容，需要重新渲染
- 修改了渲染参数（字体、颜色、排版等），需要重新渲染

**TXT 文件优先级**：
- 优先使用 `_original.txt`（原文文件，用于手动翻译后导入）
- 如果不存在，使用 `_translated.txt`（翻译文件）
- 如果都不存在，直接使用 JSON 文件中的翻译

#### 图片可编辑选项

**作用**：勾选后，程序会生成 `_translations.json` 文件，包含：
- 检测到的文本区域
- OCR 识别的原文
- 翻译结果
- 文本框位置信息

**用途**：
- 方便后续修改翻译内容
- 可以在编辑器中打开图片进行可视化编辑
- 可以使用"导入翻译并渲染"模式重新渲染

### 路径配置说明

#### 相对路径基准
- **打包版本**：相对于 `_internal` 目录
- **开发版本**：相对于项目根目录

#### 常用路径

**GPT配置文件路径**（GPT配置文件路径）：
- 默认：`examples/gpt_config-example.yaml`
- 用于配置 OpenAI/Gemini API 密钥和参数
- 示例文件包含 API Key、模型名称、代理设置等

**高质量翻译提示词**（高质量翻译提示词）：
- 默认：`dict/prompt_example.json`
- 用于高质量翻译器（OpenAI HQ/Gemini HQ）的提示词配置
- 可以自定义翻译风格和术语表

**字体路径**（字体路径）：
- 默认：`fonts` 目录
- 可以指定具体字体文件路径（如 `fonts/my_font.ttf`）
- 支持 `.ttf` 和 `.otf` 格式

**输出文件夹**：
- 默认：与输入文件相同目录
- 可以在界面中自定义输出路径

#### 工作文件路径（自动生成）

程序会在图片所在目录创建 `manga_translator_work` 文件夹，包含：

- **JSON 文件**：`manga_translator_work/json/图片名_translations.json`
  - 包含文本区域、原文、翻译、位置信息

- **原文 TXT**：`manga_translator_work/originals/图片名_original.txt`
  - 导出原文时生成

- **翻译 TXT**：`manga_translator_work/translations/图片名_translated.txt`
  - 手动翻译后保存在此

- **修复图片**：`manga_translator_work/inpainted/图片名_inpainted.png`
  - 擦除文字后的图片

---

## 🔍 调试流程

当翻译效果不理想时，可以通过详细日志查看中间处理步骤，找出问题所在。

### 开启详细日志

在"基础设置"标签页中，勾选 **详细日志** 选项。

### 调试文件说明

开启详细日志后，每次运行都会在 `result/时间戳-图片名-目标语言-翻译器/` 文件夹中生成调试文件：

#### 检测阶段

- **`detection_raw_boxes.png`**：检测器输出的原始文本框（未经过滤）
  - 显示检测器找到的所有可能的文本区域
  - 每个框用不同颜色标识

- **`bboxes_unfiltered.png`**：经过检测器筛选后的文本框（未经过 OCR 筛选）
  - 显示通过检测器置信度阈值的文本框
  - 红色边框标识

#### OCR 阶段

- **`ocrs/` 文件夹**：每个文本框的 OCR 识别图片
  - `0.png`, `1.png`, `2.png` ... 每个文件对应一个文本框
  - 可以查看 OCR 识别的具体内容
  - 垂直文字会自动旋转为水平显示

- **`bboxes.png`**：最终经过 OCR 筛选后的文本框
  - 显示成功识别出文字的文本框
  - 包含文字概率置信度信息
  - 显示文本框的阅读顺序（panel 编号）

#### 其他调试文件

- **`mask_raw.png`**：原始文本擦除蒙版
- **`mask_final.png`**：优化后的文本擦除蒙版
- **`inpaint_input.png`**：输入到修复模型的图片
- **`inpainted.png`**：擦除文字后的图片
- **`final.png`**：最终翻译结果

### 可调节参数

如果检测或识别效果不理想，可以在"高级设置"标签页中调节以下参数：

#### 检测器参数

- **文本置信度**（text_threshold）：`0.1 - 0.9`，默认 `0.5`
  - 检测器判断某个区域是否为文本的置信度阈值
  - **降低**：检测更多文本，但可能误检非文本区域
  - **提高**：只检测明显的文本，可能漏检模糊文本

- **文本框生成置信度**（box_threshold）：`0.1 - 0.9`，默认 `0.5`
  - 生成文本框的置信度阈值
  - **降低**：生成更多文本框
  - **提高**：只生成高置信度的文本框

- **Unclip 比例**（unclip_ratio）：`1.0 - 3.0`，默认 `2.5`
  - 文本框扩展比例
  - **增大**：文本框更大，包含更多周边区域
  - **减小**：文本框更紧凑，贴合文字边缘

#### OCR 参数

- **OCR 置信度**（prob）：`0.0 - 1.0`，默认 `0.1`
  - OCR 识别文字的置信度阈值
  - **降低**：保留更多识别结果，但可能包含错误识别
  - **提高**：只保留高置信度的识别结果，可能漏掉一些文字

### 调试流程示例

1. **检查检测阶段**：
   - 查看 `bboxes_unfiltered.png`，确认检测器是否找到了所有文本区域
   - 如果漏检：降低 **文本置信度** 和 **文本框生成置信度**
   - 如果误检：提高 **文本置信度** 和 **文本框生成置信度**

2. **检查 OCR 阶段**：
   - 查看 `ocrs/` 文件夹中的图片，确认每个文本框的内容
   - 查看 `bboxes.png`，确认哪些文本框被成功识别
   - 如果识别率低：降低 **OCR 置信度**，或提高 **Unclip 比例**（让文本框包含更多周边区域）
   - 如果识别错误多：提高 **OCR 置信度**

---

## 📖 参数详解

界面分为三个标签页，每个标签页包含不同的设置选项：

### 基础设置

#### 翻译器设置

- **翻译器**：选择翻译引擎
  - 离线翻译器：Sugoi、NLLB、M2M100 等
  - 在线翻译器：Google Gemini、OpenAI、DeepL、百度翻译等
  - 高质量翻译器：高质量翻译 OpenAI、高质量翻译 Gemini（推荐）

- **目标语言**：翻译的目标语言
  - 简体中文、繁体中文、英语、日语、韩语等

- **不跳过目标语言文本**：不跳过已是目标语言的文本（强制翻译）

- **GPT配置文件路径**：GPT 配置文件路径（用于 OpenAI/Gemini 翻译器）

- **高质量翻译提示词**：高质量翻译提示词文件路径（用于高质量翻译模式）

#### CLI 选项

- **详细日志**：输出详细的调试信息

- **使用 GPU**：启用 GPU 加速

- **重试次数**：错误重试次数（-1 = 无限重试）

- **忽略错误**：忽略错误继续处理

- **覆盖已存在文件**：覆盖已存在的翻译文件

- **跳过无文本图像**：跳过没有检测到文本的图片

- **图片可编辑**：保存翻译结果到 JSON 文件（用于后续编辑）

- **导入翻译**：从 JSON 文件加载翻译结果

- **导出原文**：导出原文到文本文件（用于手动翻译）

- **输出格式**：输出图片格式（PNG/JPEG/WEBP）

- **图像保存质量**：JPEG 保存质量（0-100）

- **批量大小**：批量处理大小

- **上下文页数**：翻译上下文页面数

### 高级设置

#### 检测器设置

- **文本检测器**：文本检测算法
  - **default**：默认检测器（DBNet + ResNet34）
  - **ctd**：Comic 文本检测器
  - **craft**：CRAFT 检测器

- **检测大小**：检测时的图像缩放尺寸（默认 2048，越大越准确但越慢）

- **文本阈值**：文本检测置信度阈值（0-1，越高越严格）

- **旋转图像进行检测**：旋转图像进行检测（提高检测率）

- **旋转图像以优先检测垂直文本行**：自动旋转优先检测垂直文本（适合竖排文字）

- **反转图像颜色进行检测**：反转图像颜色进行检测（适合白底黑字）

- **应用伽马校正进行检测**：应用伽马校正进行检测（提高低对比度图像检测率）

- **边界框生成阈值**：文本框生成的置信度阈值（值越低检测到的文本框越多）

- **Unclip比例**：Unclip 比例（控制文本框扩展程度）

#### 修复器设置

- **修复模型**：图像修复算法
  - **lama_large**：大型 LaMa 修复模型（推荐，效果最好）
  - **lama_mpe**：LaMa MPE 修复模型（速度快）
  - **default**：AOT 修复器（默认）

- **修复大小**：修复处理时的图像尺寸（越大效果越好但越慢）

- **修复精度**：精度设置
  - **fp32**：单精度（最准确，最慢）
  - **fp16**：半精度（平衡）
  - **bf16**：BFloat16（推荐）

#### 渲染器设置

- **排版模式**：文本排版模式
  - **智能缩放**：智能缩放（推荐，自动调整字体大小）
  - **严格边界**：严格边界（缩小字体以适应文本框）
  - **固定字体**：固定字体（扩大文本框以适应文字）
  - **完全禁用**：完全禁用（裁剪超出的文本）
  - **默认模式**：默认模式（有 Bug，不推荐）

- **对齐方式**：文本对齐方式
  - **自动**：自动对齐
  - **左对齐**：左对齐
  - **居中**：居中对齐
  - **右对齐**：右对齐

- **文本方向**：文字方向
  - **自动**：自动检测
  - **横排**：水平排列
  - **竖排**：垂直排列

- **字体路径**：字体文件路径（选择自定义字体）

- **禁用字体边框**：禁用字体边框（去除描边效果）

- **字体大小偏移量**：字体大小偏移量（调整字体大小，正数增大，负数减小）

- **字体颜色**：字体颜色（十六进制颜色代码，如 #FFFFFF）

- **行间距**：行间距（控制行与行之间的距离）

- **AI断句**：启用 AI 自动断句（禁用自动换行）

- **最小字体大小**：最小字体大小（限制字体最小尺寸）

- **最大字体大小**：最大字体大小（限制字体最大尺寸）

- **字体缩放比例**：字体缩放比例（整体缩放字体）

- **AI断句时文本居中**：AI 断句时文本居中（断句模式下居中显示）

#### 超分辨率设置

- **超分模型**：超分辨率模型
  - **waifu2x**：Waifu2x 超分模型
  - 其他超分模型

- **还原超分**：翻译后恢复原始分辨率（避免图片变大）

#### 上色器设置

- **上色模型**：上色器类型
  - **none**：不上色（默认）
  - 其他上色模型

- **上色大小**：上色处理尺寸（越大效果越好但越慢）

- **降噪强度**：去噪强度（控制降噪程度）

### 选项

#### OCR 设置

- **OCR模型**：OCR 识别模型
  - **48px**：默认模型（推荐，平衡速度和准确率）
  - **48px_ctc**：CTC 模型（识别准确率更高）
  - **mocr**：Manga OCR 专用模型（专门针对漫画优化）
  - **paddleocr**：PaddleOCR 引擎（支持多语言）

- **启用混合OCR**：启用混合 OCR（同时使用两个模型，提高准确率）

- **备用OCR**：第二个 OCR 模型（混合 OCR 时使用）

- **最小文本长度**：最小文本长度（过滤掉长度小于此值的文本）

- **忽略非气泡文本**：忽略气泡阈值（忽略非对话框内的文本）

- **文本区域最低概率 (prob)**：OCR 识别概率阈值（低于此值的文本会被过滤）

- **使用MOCR合并**：使用 MOCR 合并（合并相邻的文本区域）

- **合并-距离容忍度**：合并时的距离容忍度（控制文本区域合并的距离阈值）

- **合并-离群容忍度**：合并时的离群容忍度（控制离群文本的合并程度）

#### 全局参数

- **过滤文本 (Regex)**：文本过滤正则表达式（使用正则表达式过滤特定文本）

- **卷积核大小**：文本擦除卷积核大小（默认 3，控制文本擦除的范围）

- **遮罩扩张偏移**：蒙版膨胀偏移量（默认 70，控制文本擦除区域的扩展程度）

---

## 👨‍💻 开发者指南

### 项目结构

```
manga-translator-ui-package/
├── desktop_qt_ui/          # PyQt6 桌面应用（主界面）
│   ├── main.py            # 应用入口
│   ├── main_window.py     # 主窗口
│   ├── app_logic.py       # 业务逻辑
│   ├── editor/            # 可视化编辑器
│   ├── services/          # 服务层
│   └── widgets/           # UI 组件
├── manga_translator/       # 核心翻译引擎
│   ├── translators/       # 翻译器实现
│   ├── ocr/              # OCR 模块
│   ├── detection/        # 文本检测
│   ├── inpainting/       # 图像修复
│   └── rendering/        # 文本渲染
├── fonts/                 # 字体文件
├── models/                # AI 模型
├── examples/              # 配置示例
└── requirements_*.txt     # 依赖列表
```

### 环境配置

**系统要求：**
- Python 3.12
- Windows 10/11 或 Linux

**安装依赖：**

```bash
# CPU 版本
pip install -r requirements_cpu.txt

# GPU 版本（需要 CUDA 12.x）
pip install -r requirements_gpu.txt
```

### 运行开发版

```bash
# 运行 PyQt6 界面
python -m desktop_qt_ui.main

# 或运行旧版 CustomTkinter 界面
python -m desktop-ui.main
```

### 构建打包

```bash
# 安装 PyInstaller
pip install pyinstaller

# 构建 CPU 版本
python build_packages.py <version> --build cpu

# 构建 GPU 版本
python build_packages.py <version> --build gpu

# 示例：构建 1.6.0 版本
python build_packages.py 1.6.0 --build cpu
```

---

## 📝 许可证

本项目基于 GPL-3.0 许可证开源。

核心翻译引擎来自 [zyddnys/manga-image-translator](https://github.com/zyddnys/manga-image-translator)。

---

## 🙏 致谢

- [zyddnys/manga-image-translator](https://github.com/zyddnys/manga-image-translator) - 核心翻译引擎
- 所有贡献者和用户的支持
